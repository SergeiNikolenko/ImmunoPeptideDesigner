{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Код для оптимизации пептидов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание окужения Conda для работы всех зависимостей \n",
    "markdown что бы код автоматом не выполнялся"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip_runall"
    ],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "!conda create -n bio4 -y\n",
    "!conda activate bio4\n",
    "!conda install -c conda-forge mdtraj numpy biopython scikit-learn -y\n",
    "!conda install -c omnia mdtraj-extras -y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалить окружение Conda "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "skip_runall"
    ],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "!conda remove --name bio4 --all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск линейной последовательности"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек и функций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mdtraj.geometry import shrake_rupley"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и обработка структуры белка:\n",
    "__load_structure:__ загружает структуру из PDB-файла  \n",
    "__identify_cleavage_site:__ ищет место разреза в последовательности белка  \n",
    "__compute_sasa:__ вычисляет растворимую поверхность атомов (SASA) для каждого остатка белка  \n",
    "__find_accessible_region:__ определяет доступные для пептидов остатки белка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_structure(file_path):\n",
    "    return md.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_cleavage_site(structure, site_sequence):\n",
    "    protein_seq = structure.top.to_fasta()[0]\n",
    "    return protein_seq.find(site_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sasa(structure):\n",
    "    atom_sasa = shrake_rupley(structure, mode='atom')\n",
    "    atom_sasa = atom_sasa.flatten()\n",
    "    residue_sasa = np.zeros(structure.n_residues)\n",
    "    for atom, sasa in zip(structure.top.atoms, atom_sasa):\n",
    "        residue_sasa[atom.residue.index] += sasa\n",
    "    return residue_sasa\n",
    "\n",
    "sasa_threshold = 0.2  # Отрегулируйте по мере необходимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accessible_region(structure, cleavage_site, sasa_threshold):\n",
    "    sasa = compute_sasa(structure)\n",
    "    accessible_residues = np.where(sasa > sasa_threshold)[0]\n",
    "    return accessible_residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt_file(filename, peptide):\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(peptide + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дизайн кандидатов\n",
    "__design_candidate_peptides:__ генерирует пептиды кандидаты   \n",
    "__filter_known_antigenic_motifs:__ фильтрует пептиды, содержащие известные антигенные мотивы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def design_candidate_peptides(structure, accessible_region, peptide_length_range):\n",
    "    protein_seq = structure.top.to_fasta()[0]\n",
    "    candidate_peptides = []\n",
    "    for start_idx in accessible_region:\n",
    "        for peptide_length in peptide_length_range:\n",
    "            end_idx = start_idx + peptide_length\n",
    "            if end_idx < len(protein_seq):\n",
    "                candidate_peptides.append(protein_seq[start_idx:end_idx])\n",
    "    return candidate_peptides\n",
    "\n",
    "def filter_known_antigenic_motifs(candidate_peptides, antigenic_motifs):\n",
    "    filtered_peptides = []\n",
    "    for peptide in candidate_peptides:\n",
    "        if not any(motif in peptide for motif in antigenic_motifs):\n",
    "            filtered_peptides.append(peptide)\n",
    "    return filtered_peptides\n",
    "\n",
    "known_antigenic_motifs = [\n",
    "    \"AAAA\",\n",
    "    \"RRRR\",\n",
    "    # Из литературы реальные записать \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка иммуногенности\n",
    "__evaluate_immunogenicity:__ оценивает иммуногенност пептидов  \n",
    "__optimize_peptide_sequence:__ находит топ-N оптимизированных пептидов с наилучшей иммуногенностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_immunogenicity(peptides):\n",
    "    # Define the hydrophobicity scale\n",
    "    hydrophobicity_scale = {\n",
    "        'A': 0.47, 'R': 0.81, 'N': 0.42, 'D': 1.23, 'C': 0.77, 'Q': 0.58,\n",
    "        'E': 1.14, 'G': 0.59, 'H': 1.00, 'I': 1.41, 'L': 1.21, 'K': 0.99,\n",
    "        'M': 1.45, 'F': 1.13, 'P': 0.31, 'S': 0.39, 'T': 0.43, 'W': 1.08,\n",
    "        'Y': 0.81, 'V': 1.08\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    for peptide in peptides:\n",
    "        seq = Seq(peptide)\n",
    "        pa = ProteinAnalysis(str(seq))\n",
    "        \n",
    "        # Calculate instability index\n",
    "        instability_index = pa.instability_index()\n",
    "\n",
    "        # Calculate hydrophobicity using the hydrophobicity scale\n",
    "        hydrophobicity = np.mean([hydrophobicity_scale.get(aa, 0) for aa in peptide])\n",
    "        \n",
    "        # Calculate charge\n",
    "        charge = pa.charge_at_pH(7.4)\n",
    "        \n",
    "        # Calculate propensity to form secondary structures\n",
    "        helix, turn, sheet = pa.secondary_structure_fraction()\n",
    "        secondary_structure_score = helix + sheet\n",
    "\n",
    "        # Combine the scores using your preferred weighting\n",
    "        combined_score = instability_index + hydrophobicity + charge + secondary_structure_score\n",
    "        scores.append(combined_score)\n",
    "\n",
    "    scores = np.array(scores)\n",
    "    scores_min = np.min(scores)\n",
    "    scores_max = np.max(scores)\n",
    "    scaled_scores = (scores - scores_min) / (scores_max - scores_min)\n",
    "    return scaled_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_peptide_sequence(peptides, immunogenicity_scores, top_n=1):\n",
    "    top_peptide_indices = np.argsort(immunogenicity_scores)[::-1][:top_n]\n",
    "    top_peptides = [peptides[i] for i in top_peptide_indices]\n",
    "    top_scores = [immunogenicity_scores[i] for i in top_peptide_indices]\n",
    "    return top_peptides, top_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основной код программы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = \"c5.pdb\"\n",
    "    site_sequence = \"VNND\"\n",
    "    distance_threshold = 10\n",
    "    peptide_length_range = range(16, 101)  # Generate peptide lengths from 10 to 20 inclusive\n",
    "    \n",
    "    structure = load_structure(file_path)\n",
    "    protein_seq = structure.top.to_fasta()[0]\n",
    "\n",
    "    print(f\"Protein sequence in FASTA format:\\n>{structure.topology.chain(0)}\\n{protein_seq}\")\n",
    "    \n",
    "    #cleavage_site = identify_cleavage_site(structure, site_sequence)\n",
    "\n",
    "    cleavage_site = 73  # Directly set the cleavage site index\n",
    "\n",
    "    # Set the number of top peptides you'd like to select\n",
    "    top_n = 5\n",
    "\n",
    "    if cleavage_site == -1:\n",
    "        print(\"Cleavage site sequence not found in the protein. Please ensure the site_sequence variable is correct.\")\n",
    "    else:\n",
    "        accessible_region = find_accessible_region(structure, cleavage_site, sasa_threshold)\n",
    "        candidate_peptides = design_candidate_peptides(structure, accessible_region, peptide_length_range)\n",
    "        candidate_peptides = filter_known_antigenic_motifs(candidate_peptides, known_antigenic_motifs)\n",
    "        if not candidate_peptides:\n",
    "            print(\"No candidate peptides were generated. Please check the input parameters and try again.\")\n",
    "        else:\n",
    "\n",
    "            try:\n",
    "                with open(\"peptides.txt\", \"w\") as file:\n",
    "                    pass\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "\n",
    "            immunogenicity_scores = evaluate_immunogenicity(candidate_peptides)\n",
    "            optimized_peptides, optimized_scores = optimize_peptide_sequence(candidate_peptides, immunogenicity_scores, top_n)\n",
    "\n",
    "            print(f\"Top {top_n} optimized peptides:\")\n",
    "\n",
    "            for i, (peptide, score) in enumerate(zip(optimized_peptides, optimized_scores), start=1):\n",
    "                print(f\"{i}. Peptide: {peptide}, Score: {score:.3f}\")\n",
    "                write_txt_file(\"peptides.txt\", peptide)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание файлов fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(\"peptides\"):\n",
    "    os.makedirs(\"peptides\")\n",
    "else:\n",
    "    for filename in os.listdir(\"peptides\"):\n",
    "        os.remove(os.path.join(\"peptides\", filename))\n",
    "\n",
    "with open(\"peptides.txt\", \"r\") as f:\n",
    "    peptides = f.read().splitlines()\n",
    "\n",
    "# Write each peptide to a new file with the .fasta extension\n",
    "for i, peptide in enumerate(peptides):\n",
    "    filename = f\"peptides/peptide{i+1}.fasta\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(f\">peptide_{i+1}\\n{peptide}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ in silico\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем папку для докинга \n",
    "Или чистим от прошлых расчетов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Проверяем, существует ли папка docking\n",
    "if os.path.exists('docking'):\n",
    "    # Получаем список всех файлов и папок в папке docking\n",
    "    files = os.listdir('docking')\n",
    "    for file in files:\n",
    "        # Удаляем все файлы и папки, кроме vina.py и params.txt\n",
    "        if file not in ('vina.py', 'params.txt'):\n",
    "            path = os.path.join('docking', file)\n",
    "            if os.path.isdir(path):\n",
    "                shutil.rmtree(path)\n",
    "            else:\n",
    "                os.remove(path)\n",
    "else:\n",
    "    # Если папки docking нет, создаем ее\n",
    "    os.makedirs('docking')\n",
    "\n",
    "# Создаем папки ligands и receptors внутри папки docking\n",
    "ligands_dir = os.path.join('docking', 'ligands')\n",
    "receptors_dir = os.path.join('docking', 'receptors')\n",
    "os.makedirs(ligands_dir, exist_ok=True)\n",
    "os.makedirs(receptors_dir, exist_ok=True)\n",
    "\n",
    "# Копируем файлы vina.py и params.txt в папку docking, если их там нет\n",
    "for file_name in ('vina.py', 'params.txt'):\n",
    "    if not os.path.exists(os.path.join('docking', file_name)):\n",
    "        shutil.copy(file_name, 'docking')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразуем FASTA в PDB\n",
    "\n",
    "для этого использовать \n",
    "https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb#scrollTo=rowN0bVYLe9n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск AutoDock Vina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip_runall"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('docking')\n",
    "os.system('python vina.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
